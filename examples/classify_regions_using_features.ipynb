{
 "metadata": {
  "name": "classify_regions_using_features"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classifying brain regions based on neurosynth features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, we will classify two regions of the brain (ROIs) based on neurosynth features (i.e. words) using a linear support vector machine.\n",
      "In particular, we'll classify studies that activate medial motor regions versus those that activate ventromedial PFC. \n",
      "\n",
      "Using Nifti masks, we will select studies that activiate only each of the two regions, train a classifier to classify between the two sets of studies, and use cross-validation to estimate the classifier's performance.\n",
      "\n",
      "First, we need to load a dataset. Let's assume you have already generated one and saved it. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from neurosynth.base.dataset import Dataset\n",
      "dataset = Dataset.load('../data/pickled.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using the function \"classify_regions\" in neurosynth.analysis. Let's take a look at the argument structure:\n",
      "\n",
      "classify_regions only has two required arguments: a neurosynth dataset and a list of Nifit binary masks to use for selecting studies to classify.\n",
      "Let's give it our dataset and the path to two masks:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from neurosynth.analysis import classify\n",
      "results = classify.classify_regions(dataset, [\"../neurosynth/tests/data/medial_motor.nii.gz\", \"../neurosynth/tests/data/vmPFC.nii.gz\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "classify_regions will by default return a Python dictionary with various elements of the classification results.\n",
      "\n",
      "Most basic is the classification score, which is by default overall accuracy. Let's take a look:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results['score']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.87813479623824453"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hey! Not bad, 87% accuracy. Sounds high, right? Before we get too excited, let's look a little deeper into classify_region's default behavior by looking at the argument structure:\n",
      "\n",
      "classify_regions(dataset, masks, method='SVM', threshold=0.001, remove_overlap=True,  regularization='scale', output='summary', studies=None, features=None, class_weight=True, classifier=None, cross_val=None):\n",
      "\n",
      "Let's focus on the first few arguments: by default, a support vector machine is used as the classifier method, studies that have more than 0.1% of their peaks (i.e. any) in a mask are included, studies that activate both regions are removed, the feature vectors are regularized to having unit variance and a summary dictionary is returned.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}